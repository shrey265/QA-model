{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lck0K0pz0Sop"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndFk1H3w0bUb",
        "outputId": "776e11d5-5b54-4a0d-83a0-1dcc3c232345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/dm_audio_interspeech/2075_concatenate_dm_4featu.csv')\n",
        "df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/2075_concatenate_dm_4featu.csv')\n",
        "# mfcc_simple_mean_newdm_2075.csv\n",
        "# df = pd.read_csv('/content/drive/MyDrive/DatabaseDistorted/final_tii_all_finaldata/features/mfcc_simple_mean_newdm_2075.csv')\n",
        "\n",
        "df = df.drop(['Unnamed: 0'], axis = 1)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3u4-pxa0dky",
        "outputId": "a90c1c96-f46e-4dd3-f110-47af3c9c110d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2075, 181)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "siz=415\n",
        "df_read = df.copy()\n",
        "df1 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df1.index)\n",
        "df2 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df2.index)\n",
        "df3 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df3.index)\n",
        "df4 = df_read.sample(siz)\n",
        "df_read = df_read.drop(df4.index)\n",
        "df5 = df_read.copy()\n",
        "\n",
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "print(df3.shape)\n",
        "print(df4.shape)\n",
        "print(df5.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsolj3rF0g9a",
        "outputId": "23a7a43d-d923-4919-86c2-38baf42addaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(415, 181)\n",
            "(415, 181)\n",
            "(415, 181)\n",
            "(415, 181)\n",
            "(415, 181)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = list(df1.index)+list(df2.index)+list(df3.index)+list(df4.index)+list(df5.index)\n",
        "print(df1.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_2ItGDd0iua",
        "outputId": "5fe7a2ec-6dbd-48a8-f433-e792c9c52446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Int64Index([ 881,  453, 2004, 1353,  281,  941, 1185, 1159, 1138,  599,\n",
            "            ...\n",
            "             834, 1730,  353, 1345, 1190, 1375,  185,  701, 1671, 1982],\n",
            "           dtype='int64', length=415)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([df1,df2,df3,df4], axis=0)\n",
        "test = df5.copy()\n",
        "\n",
        "Y_train = np.array(train['class'])\n",
        "X_train= np.array(train.drop(['class'],axis=1))\n",
        "# X_train=X_train.reshape(X_train.shape[0], 1 , X_train.shape[1])\n",
        "\n",
        "Y_val=np.array(test['class'])\n",
        "X_val = np.array(test.drop(['class'],axis=1))\n",
        "# X_val=X_val.reshape(X_val.shape[0], 1 , X_val.shape[1])\n",
        "\n",
        "# Reshape your data for input to the GRU layer (assuming your data is 2D)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)"
      ],
      "metadata": {
        "id": "oL_yS3Z-0lTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_cRtr0h0ocA",
        "outputId": "1e0091ea-a1d1-46c1-b8e4-01b0d2dd7de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1660, 180, 1)\n",
            "(1660,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the GRU model for regression\n",
        "model = Sequential()\n",
        "model.add(GRU(units=64, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(GRU(units=32, return_sequences=True))\n",
        "model.add(GRU(units=16))\n",
        "model.add(Dense(1, activation='linear'))  # Linear activation for regression\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mae')"
      ],
      "metadata": {
        "id": "4lZzmZEx1UK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, epochs=1000, batch_size=64, validation_data=(X_val, Y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uS5yyXg2R5h",
        "outputId": "7596488b-0f7b-46dc-a6a6-d3d575fc7df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "26/26 [==============================] - 7s 58ms/step - loss: 10.4220 - val_loss: 9.1167\n",
            "Epoch 2/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 9.1381 - val_loss: 7.7891\n",
            "Epoch 3/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 7.5679 - val_loss: 6.0505\n",
            "Epoch 4/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 5.5066 - val_loss: 3.9282\n",
            "Epoch 5/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 3.3217 - val_loss: 2.2375\n",
            "Epoch 6/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 2.0928 - val_loss: 1.7961\n",
            "Epoch 7/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.8542 - val_loss: 1.7970\n",
            "Epoch 8/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.8336 - val_loss: 1.7839\n",
            "Epoch 9/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.8174 - val_loss: 1.7694\n",
            "Epoch 10/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.8029 - val_loss: 1.7565\n",
            "Epoch 11/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.7887 - val_loss: 1.7444\n",
            "Epoch 12/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.7748 - val_loss: 1.7332\n",
            "Epoch 13/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.7622 - val_loss: 1.7229\n",
            "Epoch 14/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.7512 - val_loss: 1.7151\n",
            "Epoch 15/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 1.7400 - val_loss: 1.7003\n",
            "Epoch 16/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.7287 - val_loss: 1.6924\n",
            "Epoch 17/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.7171 - val_loss: 1.6826\n",
            "Epoch 18/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.7076 - val_loss: 1.6774\n",
            "Epoch 19/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6989 - val_loss: 1.6661\n",
            "Epoch 20/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6897 - val_loss: 1.6614\n",
            "Epoch 21/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6817 - val_loss: 1.6548\n",
            "Epoch 22/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6738 - val_loss: 1.6459\n",
            "Epoch 23/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.6658 - val_loss: 1.6394\n",
            "Epoch 24/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6590 - val_loss: 1.6319\n",
            "Epoch 25/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6524 - val_loss: 1.6288\n",
            "Epoch 26/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6458 - val_loss: 1.6212\n",
            "Epoch 27/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.6416 - val_loss: 1.6199\n",
            "Epoch 28/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.6366 - val_loss: 1.6157\n",
            "Epoch 29/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6338 - val_loss: 1.6122\n",
            "Epoch 30/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6320 - val_loss: 1.6139\n",
            "Epoch 31/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6305 - val_loss: 1.6139\n",
            "Epoch 32/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6285 - val_loss: 1.6095\n",
            "Epoch 33/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6278 - val_loss: 1.6086\n",
            "Epoch 34/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.6258 - val_loss: 1.6102\n",
            "Epoch 35/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.6242 - val_loss: 1.6093\n",
            "Epoch 36/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.6226 - val_loss: 1.6068\n",
            "Epoch 37/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.6213 - val_loss: 1.6026\n",
            "Epoch 38/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.6206 - val_loss: 1.6050\n",
            "Epoch 39/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.6171 - val_loss: 1.6021\n",
            "Epoch 40/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6155 - val_loss: 1.6014\n",
            "Epoch 41/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.6131 - val_loss: 1.6017\n",
            "Epoch 42/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.6117 - val_loss: 1.5971\n",
            "Epoch 43/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6078 - val_loss: 1.6034\n",
            "Epoch 44/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6045 - val_loss: 1.5954\n",
            "Epoch 45/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.6030 - val_loss: 1.5895\n",
            "Epoch 46/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.6005 - val_loss: 1.5986\n",
            "Epoch 47/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5951 - val_loss: 1.5844\n",
            "Epoch 48/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5899 - val_loss: 1.5898\n",
            "Epoch 49/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.5865 - val_loss: 1.5812\n",
            "Epoch 50/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5813 - val_loss: 1.5826\n",
            "Epoch 51/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5763 - val_loss: 1.5791\n",
            "Epoch 52/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.5709 - val_loss: 1.5738\n",
            "Epoch 53/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5633 - val_loss: 1.5706\n",
            "Epoch 54/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5574 - val_loss: 1.5704\n",
            "Epoch 55/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.5502 - val_loss: 1.5633\n",
            "Epoch 56/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.5428 - val_loss: 1.5611\n",
            "Epoch 57/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.5365 - val_loss: 1.5567\n",
            "Epoch 58/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.5291 - val_loss: 1.5555\n",
            "Epoch 59/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 1.5203 - val_loss: 1.5414\n",
            "Epoch 60/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.5160 - val_loss: 1.5471\n",
            "Epoch 61/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.5075 - val_loss: 1.5414\n",
            "Epoch 62/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.4973 - val_loss: 1.5247\n",
            "Epoch 63/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.4907 - val_loss: 1.5319\n",
            "Epoch 64/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.4847 - val_loss: 1.5321\n",
            "Epoch 65/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.4763 - val_loss: 1.5035\n",
            "Epoch 66/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.4704 - val_loss: 1.4900\n",
            "Epoch 67/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.4580 - val_loss: 1.4978\n",
            "Epoch 68/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.4474 - val_loss: 1.4800\n",
            "Epoch 69/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.4366 - val_loss: 1.4742\n",
            "Epoch 70/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.4287 - val_loss: 1.4645\n",
            "Epoch 71/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.4179 - val_loss: 1.4529\n",
            "Epoch 72/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.4062 - val_loss: 1.4434\n",
            "Epoch 73/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3995 - val_loss: 1.4269\n",
            "Epoch 74/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3928 - val_loss: 1.4277\n",
            "Epoch 75/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3843 - val_loss: 1.4111\n",
            "Epoch 76/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3765 - val_loss: 1.4191\n",
            "Epoch 77/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3628 - val_loss: 1.4034\n",
            "Epoch 78/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3663 - val_loss: 1.4071\n",
            "Epoch 79/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3543 - val_loss: 1.4073\n",
            "Epoch 80/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3503 - val_loss: 1.3889\n",
            "Epoch 81/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3470 - val_loss: 1.3937\n",
            "Epoch 82/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3446 - val_loss: 1.4201\n",
            "Epoch 83/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3421 - val_loss: 1.3923\n",
            "Epoch 84/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.3461 - val_loss: 1.3948\n",
            "Epoch 85/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3370 - val_loss: 1.4299\n",
            "Epoch 86/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3448 - val_loss: 1.4366\n",
            "Epoch 87/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.3408 - val_loss: 1.4220\n",
            "Epoch 88/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.3365 - val_loss: 1.3812\n",
            "Epoch 89/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 1.3334 - val_loss: 1.3640\n",
            "Epoch 90/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3351 - val_loss: 1.3662\n",
            "Epoch 91/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3316 - val_loss: 1.3695\n",
            "Epoch 92/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3298 - val_loss: 1.3838\n",
            "Epoch 93/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3337 - val_loss: 1.3636\n",
            "Epoch 94/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3280 - val_loss: 1.3837\n",
            "Epoch 95/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3331 - val_loss: 1.3866\n",
            "Epoch 96/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3326 - val_loss: 1.3976\n",
            "Epoch 97/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3323 - val_loss: 1.3760\n",
            "Epoch 98/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3302 - val_loss: 1.3647\n",
            "Epoch 99/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3338 - val_loss: 1.4324\n",
            "Epoch 100/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3356 - val_loss: 1.4561\n",
            "Epoch 101/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3304 - val_loss: 1.3636\n",
            "Epoch 102/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3256 - val_loss: 1.3944\n",
            "Epoch 103/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3295 - val_loss: 1.3974\n",
            "Epoch 104/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3301 - val_loss: 1.3894\n",
            "Epoch 105/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3264 - val_loss: 1.3590\n",
            "Epoch 106/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3355 - val_loss: 1.3593\n",
            "Epoch 107/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3331 - val_loss: 1.4365\n",
            "Epoch 108/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3270 - val_loss: 1.3727\n",
            "Epoch 109/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3254 - val_loss: 1.3700\n",
            "Epoch 110/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3246 - val_loss: 1.3718\n",
            "Epoch 111/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3237 - val_loss: 1.3950\n",
            "Epoch 112/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3293 - val_loss: 1.3848\n",
            "Epoch 113/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3236 - val_loss: 1.3646\n",
            "Epoch 114/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3235 - val_loss: 1.3680\n",
            "Epoch 115/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3235 - val_loss: 1.3560\n",
            "Epoch 116/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3238 - val_loss: 1.3838\n",
            "Epoch 117/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3244 - val_loss: 1.3611\n",
            "Epoch 118/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3261 - val_loss: 1.3759\n",
            "Epoch 119/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3259 - val_loss: 1.3593\n",
            "Epoch 120/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3216 - val_loss: 1.3666\n",
            "Epoch 121/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3236 - val_loss: 1.3549\n",
            "Epoch 122/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3288 - val_loss: 1.3492\n",
            "Epoch 123/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3284 - val_loss: 1.3499\n",
            "Epoch 124/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3196 - val_loss: 1.3763\n",
            "Epoch 125/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3202 - val_loss: 1.3658\n",
            "Epoch 126/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3189 - val_loss: 1.3881\n",
            "Epoch 127/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3213 - val_loss: 1.3586\n",
            "Epoch 128/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3179 - val_loss: 1.3756\n",
            "Epoch 129/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3221 - val_loss: 1.3532\n",
            "Epoch 130/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3214 - val_loss: 1.3544\n",
            "Epoch 131/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3202 - val_loss: 1.3797\n",
            "Epoch 132/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3193 - val_loss: 1.3567\n",
            "Epoch 133/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.3169 - val_loss: 1.3567\n",
            "Epoch 134/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3232 - val_loss: 1.3453\n",
            "Epoch 135/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3225 - val_loss: 1.3505\n",
            "Epoch 136/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3226 - val_loss: 1.3458\n",
            "Epoch 137/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3226 - val_loss: 1.3478\n",
            "Epoch 138/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 1.3186 - val_loss: 1.3589\n",
            "Epoch 139/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3151 - val_loss: 1.3708\n",
            "Epoch 140/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3160 - val_loss: 1.3506\n",
            "Epoch 141/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3247 - val_loss: 1.3490\n",
            "Epoch 142/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3171 - val_loss: 1.3696\n",
            "Epoch 143/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3156 - val_loss: 1.3470\n",
            "Epoch 144/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3168 - val_loss: 1.3583\n",
            "Epoch 145/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3196 - val_loss: 1.3855\n",
            "Epoch 146/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3128 - val_loss: 1.3459\n",
            "Epoch 147/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3180 - val_loss: 1.3666\n",
            "Epoch 148/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3175 - val_loss: 1.3494\n",
            "Epoch 149/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3175 - val_loss: 1.3552\n",
            "Epoch 150/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3136 - val_loss: 1.3482\n",
            "Epoch 151/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3133 - val_loss: 1.3508\n",
            "Epoch 152/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3124 - val_loss: 1.3682\n",
            "Epoch 153/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3154 - val_loss: 1.3714\n",
            "Epoch 154/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3168 - val_loss: 1.3632\n",
            "Epoch 155/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3157 - val_loss: 1.3597\n",
            "Epoch 156/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3164 - val_loss: 1.3429\n",
            "Epoch 157/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.3122 - val_loss: 1.3557\n",
            "Epoch 158/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3125 - val_loss: 1.3499\n",
            "Epoch 159/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.3146 - val_loss: 1.3692\n",
            "Epoch 160/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.3111 - val_loss: 1.3448\n",
            "Epoch 161/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.3114 - val_loss: 1.3422\n",
            "Epoch 162/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.3127 - val_loss: 1.3710\n",
            "Epoch 163/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3161 - val_loss: 1.3828\n",
            "Epoch 164/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3094 - val_loss: 1.3391\n",
            "Epoch 165/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3131 - val_loss: 1.3410\n",
            "Epoch 166/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3140 - val_loss: 1.3498\n",
            "Epoch 167/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3101 - val_loss: 1.3479\n",
            "Epoch 168/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3092 - val_loss: 1.3536\n",
            "Epoch 169/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3105 - val_loss: 1.3389\n",
            "Epoch 170/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3084 - val_loss: 1.3410\n",
            "Epoch 171/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3092 - val_loss: 1.3391\n",
            "Epoch 172/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3102 - val_loss: 1.3730\n",
            "Epoch 173/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3065 - val_loss: 1.3359\n",
            "Epoch 174/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3089 - val_loss: 1.3334\n",
            "Epoch 175/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3059 - val_loss: 1.3674\n",
            "Epoch 176/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.3112 - val_loss: 1.3773\n",
            "Epoch 177/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3120 - val_loss: 1.3516\n",
            "Epoch 178/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.3059 - val_loss: 1.3445\n",
            "Epoch 179/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.3033 - val_loss: 1.3448\n",
            "Epoch 180/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.3081 - val_loss: 1.3362\n",
            "Epoch 181/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.3043 - val_loss: 1.3367\n",
            "Epoch 182/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 1.3018 - val_loss: 1.3247\n",
            "Epoch 183/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 1.3054 - val_loss: 1.3249\n",
            "Epoch 184/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.3050 - val_loss: 1.3340\n",
            "Epoch 185/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.2995 - val_loss: 1.3454\n",
            "Epoch 186/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 1.2988 - val_loss: 1.3290\n",
            "Epoch 187/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.2953 - val_loss: 1.3397\n",
            "Epoch 188/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.2995 - val_loss: 1.3286\n",
            "Epoch 189/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.2937 - val_loss: 1.3130\n",
            "Epoch 190/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.2844 - val_loss: 1.3254\n",
            "Epoch 191/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.2827 - val_loss: 1.2834\n",
            "Epoch 192/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.2710 - val_loss: 1.2695\n",
            "Epoch 193/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.2509 - val_loss: 1.2889\n",
            "Epoch 194/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.2184 - val_loss: 1.1852\n",
            "Epoch 195/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.1757 - val_loss: 1.1293\n",
            "Epoch 196/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.1344 - val_loss: 1.0519\n",
            "Epoch 197/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.1354 - val_loss: 1.0249\n",
            "Epoch 198/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.1011 - val_loss: 1.0119\n",
            "Epoch 199/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0957 - val_loss: 1.0019\n",
            "Epoch 200/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0914 - val_loss: 1.0058\n",
            "Epoch 201/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0910 - val_loss: 1.0215\n",
            "Epoch 202/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0771 - val_loss: 0.9920\n",
            "Epoch 203/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.1101 - val_loss: 1.0173\n",
            "Epoch 204/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 1.0794 - val_loss: 0.9805\n",
            "Epoch 205/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0706 - val_loss: 0.9992\n",
            "Epoch 206/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.0809 - val_loss: 0.9802\n",
            "Epoch 207/1000\n",
            "26/26 [==============================] - 1s 33ms/step - loss: 1.0611 - val_loss: 0.9899\n",
            "Epoch 208/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0606 - val_loss: 1.0294\n",
            "Epoch 209/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0630 - val_loss: 0.9724\n",
            "Epoch 210/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.0530 - val_loss: 0.9675\n",
            "Epoch 211/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.0533 - val_loss: 1.0107\n",
            "Epoch 212/1000\n",
            "26/26 [==============================] - 1s 44ms/step - loss: 1.0544 - val_loss: 0.9599\n",
            "Epoch 213/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.0505 - val_loss: 1.0154\n",
            "Epoch 214/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 1.0465 - val_loss: 0.9719\n",
            "Epoch 215/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0602 - val_loss: 0.9737\n",
            "Epoch 216/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 1.0503 - val_loss: 0.9625\n",
            "Epoch 217/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0473 - val_loss: 0.9545\n",
            "Epoch 218/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 1.0444 - val_loss: 0.9529\n",
            "Epoch 219/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.0629 - val_loss: 0.9549\n",
            "Epoch 220/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.0727 - val_loss: 0.9542\n",
            "Epoch 221/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.0468 - val_loss: 0.9916\n",
            "Epoch 222/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.0467 - val_loss: 0.9929\n",
            "Epoch 223/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.0385 - val_loss: 0.9575\n",
            "Epoch 224/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0458 - val_loss: 0.9457\n",
            "Epoch 225/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 1.0391 - val_loss: 0.9475\n",
            "Epoch 226/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0320 - val_loss: 0.9442\n",
            "Epoch 227/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0358 - val_loss: 0.9597\n",
            "Epoch 228/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0365 - val_loss: 0.9454\n",
            "Epoch 229/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 1.0457 - val_loss: 0.9411\n",
            "Epoch 230/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 1.0371 - val_loss: 0.9425\n",
            "Epoch 231/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0275 - val_loss: 0.9990\n",
            "Epoch 232/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.0350 - val_loss: 0.9452\n",
            "Epoch 233/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0243 - val_loss: 0.9379\n",
            "Epoch 234/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.0227 - val_loss: 0.9508\n",
            "Epoch 235/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0253 - val_loss: 0.9335\n",
            "Epoch 236/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0199 - val_loss: 0.9751\n",
            "Epoch 237/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0308 - val_loss: 0.9397\n",
            "Epoch 238/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0374 - val_loss: 1.0581\n",
            "Epoch 239/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0325 - val_loss: 0.9344\n",
            "Epoch 240/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0255 - val_loss: 0.9531\n",
            "Epoch 241/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0392 - val_loss: 0.9327\n",
            "Epoch 242/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0173 - val_loss: 0.9307\n",
            "Epoch 243/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0125 - val_loss: 0.9326\n",
            "Epoch 244/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 1.0155 - val_loss: 0.9378\n",
            "Epoch 245/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0256 - val_loss: 0.9233\n",
            "Epoch 246/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.0275 - val_loss: 0.9450\n",
            "Epoch 247/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0355 - val_loss: 0.9593\n",
            "Epoch 248/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0118 - val_loss: 0.9537\n",
            "Epoch 249/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 1.0169 - val_loss: 0.9198\n",
            "Epoch 250/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0110 - val_loss: 0.9180\n",
            "Epoch 251/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0074 - val_loss: 0.9296\n",
            "Epoch 252/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 1.0213 - val_loss: 0.9510\n",
            "Epoch 253/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 1.0149 - val_loss: 0.9197\n",
            "Epoch 254/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 1.0106 - val_loss: 0.9126\n",
            "Epoch 255/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0048 - val_loss: 0.9170\n",
            "Epoch 256/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0125 - val_loss: 0.9587\n",
            "Epoch 257/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0189 - val_loss: 0.9147\n",
            "Epoch 258/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0018 - val_loss: 0.9207\n",
            "Epoch 259/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0081 - val_loss: 0.9245\n",
            "Epoch 260/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0188 - val_loss: 0.9079\n",
            "Epoch 261/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0031 - val_loss: 0.9531\n",
            "Epoch 262/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0024 - val_loss: 0.9272\n",
            "Epoch 263/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0038 - val_loss: 0.9119\n",
            "Epoch 264/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0035 - val_loss: 0.9038\n",
            "Epoch 265/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9994 - val_loss: 0.9029\n",
            "Epoch 266/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 1.0050 - val_loss: 0.9375\n",
            "Epoch 267/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0231 - val_loss: 0.9079\n",
            "Epoch 268/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0117 - val_loss: 0.9041\n",
            "Epoch 269/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9988 - val_loss: 0.9014\n",
            "Epoch 270/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9954 - val_loss: 0.9008\n",
            "Epoch 271/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 1.0043 - val_loss: 0.9040\n",
            "Epoch 272/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9999 - val_loss: 0.9069\n",
            "Epoch 273/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.9917 - val_loss: 0.8988\n",
            "Epoch 274/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9834 - val_loss: 0.8993\n",
            "Epoch 275/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9821 - val_loss: 0.9320\n",
            "Epoch 276/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9983 - val_loss: 0.9450\n",
            "Epoch 277/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 1.0073 - val_loss: 0.9022\n",
            "Epoch 278/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.9852 - val_loss: 0.8964\n",
            "Epoch 279/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9871 - val_loss: 0.8950\n",
            "Epoch 280/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9807 - val_loss: 0.8958\n",
            "Epoch 281/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9802 - val_loss: 0.9033\n",
            "Epoch 282/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9824 - val_loss: 0.8913\n",
            "Epoch 283/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9799 - val_loss: 0.8888\n",
            "Epoch 284/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9838 - val_loss: 0.8889\n",
            "Epoch 285/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9927 - val_loss: 0.9749\n",
            "Epoch 286/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9779 - val_loss: 0.8967\n",
            "Epoch 287/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9861 - val_loss: 0.8964\n",
            "Epoch 288/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9814 - val_loss: 0.8863\n",
            "Epoch 289/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9706 - val_loss: 0.9514\n",
            "Epoch 290/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 1.0180 - val_loss: 0.9052\n",
            "Epoch 291/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.9829 - val_loss: 0.8977\n",
            "Epoch 292/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.9755 - val_loss: 0.8816\n",
            "Epoch 293/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9744 - val_loss: 0.8878\n",
            "Epoch 294/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.9800 - val_loss: 0.9496\n",
            "Epoch 295/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9772 - val_loss: 0.8863\n",
            "Epoch 296/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9761 - val_loss: 0.8845\n",
            "Epoch 297/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9838 - val_loss: 0.8914\n",
            "Epoch 298/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9707 - val_loss: 0.8819\n",
            "Epoch 299/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9731 - val_loss: 0.8782\n",
            "Epoch 300/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9694 - val_loss: 0.8885\n",
            "Epoch 301/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.9750 - val_loss: 0.8767\n",
            "Epoch 302/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.9766 - val_loss: 0.8787\n",
            "Epoch 303/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9870 - val_loss: 0.9036\n",
            "Epoch 304/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9762 - val_loss: 0.8907\n",
            "Epoch 305/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9663 - val_loss: 0.8740\n",
            "Epoch 306/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9643 - val_loss: 0.8708\n",
            "Epoch 307/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9656 - val_loss: 0.8711\n",
            "Epoch 308/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9605 - val_loss: 0.8743\n",
            "Epoch 309/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9719 - val_loss: 0.9196\n",
            "Epoch 310/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9682 - val_loss: 0.8688\n",
            "Epoch 311/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9626 - val_loss: 0.9205\n",
            "Epoch 312/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9541 - val_loss: 0.8856\n",
            "Epoch 313/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9681 - val_loss: 0.8807\n",
            "Epoch 314/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9572 - val_loss: 0.8748\n",
            "Epoch 315/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9542 - val_loss: 0.8906\n",
            "Epoch 316/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9602 - val_loss: 0.8852\n",
            "Epoch 317/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9604 - val_loss: 0.8665\n",
            "Epoch 318/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9495 - val_loss: 0.8572\n",
            "Epoch 319/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9542 - val_loss: 0.9084\n",
            "Epoch 320/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9635 - val_loss: 0.9202\n",
            "Epoch 321/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9676 - val_loss: 0.8805\n",
            "Epoch 322/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9607 - val_loss: 0.9015\n",
            "Epoch 323/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9670 - val_loss: 0.8680\n",
            "Epoch 324/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9486 - val_loss: 0.8554\n",
            "Epoch 325/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9543 - val_loss: 0.8591\n",
            "Epoch 326/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9450 - val_loss: 0.9465\n",
            "Epoch 327/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.9529 - val_loss: 0.8540\n",
            "Epoch 328/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9449 - val_loss: 0.8762\n",
            "Epoch 329/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9535 - val_loss: 0.8516\n",
            "Epoch 330/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9465 - val_loss: 0.8680\n",
            "Epoch 331/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9516 - val_loss: 0.8822\n",
            "Epoch 332/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9885 - val_loss: 0.9218\n",
            "Epoch 333/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9604 - val_loss: 0.8705\n",
            "Epoch 334/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9399 - val_loss: 0.8548\n",
            "Epoch 335/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9554 - val_loss: 0.9682\n",
            "Epoch 336/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9662 - val_loss: 0.8742\n",
            "Epoch 337/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9516 - val_loss: 0.8566\n",
            "Epoch 338/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.9405 - val_loss: 0.8577\n",
            "Epoch 339/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9374 - val_loss: 0.8472\n",
            "Epoch 340/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9462 - val_loss: 0.8901\n",
            "Epoch 341/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9387 - val_loss: 0.8467\n",
            "Epoch 342/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9384 - val_loss: 0.8450\n",
            "Epoch 343/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9412 - val_loss: 0.8578\n",
            "Epoch 344/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9498 - val_loss: 0.8480\n",
            "Epoch 345/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9426 - val_loss: 0.8477\n",
            "Epoch 346/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9379 - val_loss: 0.8573\n",
            "Epoch 347/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9385 - val_loss: 0.8436\n",
            "Epoch 348/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9373 - val_loss: 0.8420\n",
            "Epoch 349/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9408 - val_loss: 0.8419\n",
            "Epoch 350/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9501 - val_loss: 0.9397\n",
            "Epoch 351/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.9366 - val_loss: 0.8595\n",
            "Epoch 352/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9480 - val_loss: 0.8816\n",
            "Epoch 353/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9582 - val_loss: 0.9023\n",
            "Epoch 354/1000\n",
            "26/26 [==============================] - 0s 19ms/step - loss: 0.9478 - val_loss: 1.0341\n",
            "Epoch 355/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9667 - val_loss: 0.8507\n",
            "Epoch 356/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9363 - val_loss: 0.8470\n",
            "Epoch 357/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9311 - val_loss: 0.8542\n",
            "Epoch 358/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9399 - val_loss: 0.8697\n",
            "Epoch 359/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9417 - val_loss: 0.8959\n",
            "Epoch 360/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9416 - val_loss: 0.8427\n",
            "Epoch 361/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9473 - val_loss: 0.8924\n",
            "Epoch 362/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9690 - val_loss: 0.8728\n",
            "Epoch 363/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9298 - val_loss: 0.8644\n",
            "Epoch 364/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9301 - val_loss: 0.8516\n",
            "Epoch 365/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9380 - val_loss: 0.8526\n",
            "Epoch 366/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9384 - val_loss: 0.8405\n",
            "Epoch 367/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9228 - val_loss: 0.8747\n",
            "Epoch 368/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9351 - val_loss: 0.8605\n",
            "Epoch 369/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9310 - val_loss: 0.8390\n",
            "Epoch 370/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.9332 - val_loss: 0.8764\n",
            "Epoch 371/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9275 - val_loss: 0.8393\n",
            "Epoch 372/1000\n",
            "26/26 [==============================] - 1s 33ms/step - loss: 0.9227 - val_loss: 0.8667\n",
            "Epoch 373/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.9476 - val_loss: 0.8591\n",
            "Epoch 374/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.9299 - val_loss: 0.8644\n",
            "Epoch 375/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.9273 - val_loss: 0.8723\n",
            "Epoch 376/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9233 - val_loss: 0.8467\n",
            "Epoch 377/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9294 - val_loss: 0.8978\n",
            "Epoch 378/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9367 - val_loss: 0.8798\n",
            "Epoch 379/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9422 - val_loss: 0.9075\n",
            "Epoch 380/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9335 - val_loss: 0.8446\n",
            "Epoch 381/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9312 - val_loss: 0.8465\n",
            "Epoch 382/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9152 - val_loss: 0.8434\n",
            "Epoch 383/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9210 - val_loss: 0.9069\n",
            "Epoch 384/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9155 - val_loss: 0.8419\n",
            "Epoch 385/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9277 - val_loss: 0.8399\n",
            "Epoch 386/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9172 - val_loss: 0.8367\n",
            "Epoch 387/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9144 - val_loss: 0.8355\n",
            "Epoch 388/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9253 - val_loss: 0.8552\n",
            "Epoch 389/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9321 - val_loss: 0.8444\n",
            "Epoch 390/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9240 - val_loss: 0.8964\n",
            "Epoch 391/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9159 - val_loss: 0.8408\n",
            "Epoch 392/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9283 - val_loss: 0.8342\n",
            "Epoch 393/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9249 - val_loss: 0.8475\n",
            "Epoch 394/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9163 - val_loss: 0.8344\n",
            "Epoch 395/1000\n",
            "26/26 [==============================] - 2s 65ms/step - loss: 0.9195 - val_loss: 0.8344\n",
            "Epoch 396/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.9178 - val_loss: 0.8383\n",
            "Epoch 397/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.9192 - val_loss: 0.8365\n",
            "Epoch 398/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9124 - val_loss: 0.8301\n",
            "Epoch 399/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9118 - val_loss: 0.8391\n",
            "Epoch 400/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9112 - val_loss: 0.8297\n",
            "Epoch 401/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9176 - val_loss: 0.8521\n",
            "Epoch 402/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9111 - val_loss: 0.8697\n",
            "Epoch 403/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9091 - val_loss: 0.8361\n",
            "Epoch 404/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9068 - val_loss: 0.8281\n",
            "Epoch 405/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9348 - val_loss: 0.8339\n",
            "Epoch 406/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9126 - val_loss: 0.8553\n",
            "Epoch 407/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9093 - val_loss: 0.8587\n",
            "Epoch 408/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9027 - val_loss: 0.8309\n",
            "Epoch 409/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9122 - val_loss: 0.8297\n",
            "Epoch 410/1000\n",
            "26/26 [==============================] - 1s 42ms/step - loss: 0.9197 - val_loss: 0.8457\n",
            "Epoch 411/1000\n",
            "26/26 [==============================] - 1s 37ms/step - loss: 0.9204 - val_loss: 0.8266\n",
            "Epoch 412/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9104 - val_loss: 0.8563\n",
            "Epoch 413/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9204 - val_loss: 0.8258\n",
            "Epoch 414/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9035 - val_loss: 0.8291\n",
            "Epoch 415/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.9025 - val_loss: 0.8429\n",
            "Epoch 416/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9168 - val_loss: 0.8865\n",
            "Epoch 417/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.9152 - val_loss: 0.8453\n",
            "Epoch 418/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.9183 - val_loss: 0.8602\n",
            "Epoch 419/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.9167 - val_loss: 0.8284\n",
            "Epoch 420/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9091 - val_loss: 0.8271\n",
            "Epoch 421/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9025 - val_loss: 0.8270\n",
            "Epoch 422/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9092 - val_loss: 0.8723\n",
            "Epoch 423/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9233 - val_loss: 0.8563\n",
            "Epoch 424/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9026 - val_loss: 0.8490\n",
            "Epoch 425/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9021 - val_loss: 0.8910\n",
            "Epoch 426/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8931 - val_loss: 0.8237\n",
            "Epoch 427/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9021 - val_loss: 0.8764\n",
            "Epoch 428/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.9078 - val_loss: 0.8476\n",
            "Epoch 429/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8905 - val_loss: 0.8221\n",
            "Epoch 430/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9016 - val_loss: 0.9154\n",
            "Epoch 431/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8972 - val_loss: 0.9079\n",
            "Epoch 432/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9086 - val_loss: 0.8378\n",
            "Epoch 433/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8994 - val_loss: 0.8649\n",
            "Epoch 434/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9041 - val_loss: 0.8362\n",
            "Epoch 435/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8944 - val_loss: 0.8284\n",
            "Epoch 436/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8854 - val_loss: 0.8236\n",
            "Epoch 437/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.8861 - val_loss: 0.8220\n",
            "Epoch 438/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8945 - val_loss: 0.8325\n",
            "Epoch 439/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8929 - val_loss: 0.8195\n",
            "Epoch 440/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8848 - val_loss: 0.8771\n",
            "Epoch 441/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8870 - val_loss: 0.8198\n",
            "Epoch 442/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8926 - val_loss: 0.8206\n",
            "Epoch 443/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8869 - val_loss: 0.8921\n",
            "Epoch 444/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.9259 - val_loss: 0.8253\n",
            "Epoch 445/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9109 - val_loss: 0.8803\n",
            "Epoch 446/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9131 - val_loss: 0.8434\n",
            "Epoch 447/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8842 - val_loss: 0.8206\n",
            "Epoch 448/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8931 - val_loss: 0.8282\n",
            "Epoch 449/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8867 - val_loss: 0.8377\n",
            "Epoch 450/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8891 - val_loss: 0.8172\n",
            "Epoch 451/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8814 - val_loss: 0.8398\n",
            "Epoch 452/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8816 - val_loss: 0.8404\n",
            "Epoch 453/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.8909 - val_loss: 0.8372\n",
            "Epoch 454/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8767 - val_loss: 0.8176\n",
            "Epoch 455/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8723 - val_loss: 0.8156\n",
            "Epoch 456/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8896 - val_loss: 0.8210\n",
            "Epoch 457/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8787 - val_loss: 0.8355\n",
            "Epoch 458/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8719 - val_loss: 0.8156\n",
            "Epoch 459/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8816 - val_loss: 0.8417\n",
            "Epoch 460/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.8732 - val_loss: 0.8496\n",
            "Epoch 461/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8780 - val_loss: 0.8503\n",
            "Epoch 462/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.8691 - val_loss: 0.8533\n",
            "Epoch 463/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8661 - val_loss: 0.8168\n",
            "Epoch 464/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8630 - val_loss: 0.8158\n",
            "Epoch 465/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8630 - val_loss: 0.8244\n",
            "Epoch 466/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.8730 - val_loss: 0.8080\n",
            "Epoch 467/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8670 - val_loss: 0.8414\n",
            "Epoch 468/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8635 - val_loss: 0.8255\n",
            "Epoch 469/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8687 - val_loss: 0.8090\n",
            "Epoch 470/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8616 - val_loss: 0.8694\n",
            "Epoch 471/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8668 - val_loss: 0.9363\n",
            "Epoch 472/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8817 - val_loss: 0.8560\n",
            "Epoch 473/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8653 - val_loss: 0.8126\n",
            "Epoch 474/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8641 - val_loss: 0.8178\n",
            "Epoch 475/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8657 - val_loss: 0.8252\n",
            "Epoch 476/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8684 - val_loss: 0.8833\n",
            "Epoch 477/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8691 - val_loss: 0.8125\n",
            "Epoch 478/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8809 - val_loss: 0.8398\n",
            "Epoch 479/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8777 - val_loss: 0.8534\n",
            "Epoch 480/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8652 - val_loss: 0.8082\n",
            "Epoch 481/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8619 - val_loss: 0.8126\n",
            "Epoch 482/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8610 - val_loss: 0.9269\n",
            "Epoch 483/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8684 - val_loss: 0.8188\n",
            "Epoch 484/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 0.8802 - val_loss: 0.8210\n",
            "Epoch 485/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8607 - val_loss: 0.8297\n",
            "Epoch 486/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8676 - val_loss: 0.8302\n",
            "Epoch 487/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.8631 - val_loss: 0.8085\n",
            "Epoch 488/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8614 - val_loss: 0.8065\n",
            "Epoch 489/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.8645 - val_loss: 0.8843\n",
            "Epoch 490/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.8598 - val_loss: 0.8102\n",
            "Epoch 491/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8564 - val_loss: 0.8084\n",
            "Epoch 492/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8508 - val_loss: 0.8106\n",
            "Epoch 493/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8576 - val_loss: 0.8059\n",
            "Epoch 494/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8555 - val_loss: 0.8116\n",
            "Epoch 495/1000\n",
            "26/26 [==============================] - 1s 19ms/step - loss: 0.8541 - val_loss: 0.8194\n",
            "Epoch 496/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8548 - val_loss: 0.8465\n",
            "Epoch 497/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8656 - val_loss: 0.8097\n",
            "Epoch 498/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8485 - val_loss: 0.8084\n",
            "Epoch 499/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8559 - val_loss: 0.8100\n",
            "Epoch 500/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8688 - val_loss: 0.8061\n",
            "Epoch 501/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8529 - val_loss: 0.8136\n",
            "Epoch 502/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8515 - val_loss: 0.8149\n",
            "Epoch 503/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8425 - val_loss: 0.8205\n",
            "Epoch 504/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8410 - val_loss: 0.8185\n",
            "Epoch 505/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8463 - val_loss: 0.8052\n",
            "Epoch 506/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8435 - val_loss: 0.8356\n",
            "Epoch 507/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8550 - val_loss: 0.8220\n",
            "Epoch 508/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.8434 - val_loss: 0.8076\n",
            "Epoch 509/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8425 - val_loss: 0.8090\n",
            "Epoch 510/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.8472 - val_loss: 0.8405\n",
            "Epoch 511/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8448 - val_loss: 0.8100\n",
            "Epoch 512/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8547 - val_loss: 0.8107\n",
            "Epoch 513/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8488 - val_loss: 0.8092\n",
            "Epoch 514/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8467 - val_loss: 0.8093\n",
            "Epoch 515/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8404 - val_loss: 0.8097\n",
            "Epoch 516/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8512 - val_loss: 0.8187\n",
            "Epoch 517/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8382 - val_loss: 0.8622\n",
            "Epoch 518/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8495 - val_loss: 0.8075\n",
            "Epoch 519/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8344 - val_loss: 0.8266\n",
            "Epoch 520/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8403 - val_loss: 0.8106\n",
            "Epoch 521/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8359 - val_loss: 0.8248\n",
            "Epoch 522/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8393 - val_loss: 0.8624\n",
            "Epoch 523/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8429 - val_loss: 0.8070\n",
            "Epoch 524/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.9055 - val_loss: 0.8478\n",
            "Epoch 525/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8721 - val_loss: 0.8067\n",
            "Epoch 526/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8368 - val_loss: 0.8260\n",
            "Epoch 527/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8359 - val_loss: 0.8045\n",
            "Epoch 528/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8337 - val_loss: 0.8168\n",
            "Epoch 529/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8515 - val_loss: 0.8126\n",
            "Epoch 530/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8326 - val_loss: 0.8042\n",
            "Epoch 531/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8575 - val_loss: 0.9796\n",
            "Epoch 532/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8732 - val_loss: 0.8636\n",
            "Epoch 533/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8389 - val_loss: 0.8138\n",
            "Epoch 534/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8399 - val_loss: 0.8247\n",
            "Epoch 535/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8401 - val_loss: 0.8071\n",
            "Epoch 536/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8429 - val_loss: 0.8803\n",
            "Epoch 537/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8387 - val_loss: 0.8604\n",
            "Epoch 538/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8296 - val_loss: 0.8286\n",
            "Epoch 539/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8316 - val_loss: 0.8055\n",
            "Epoch 540/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8347 - val_loss: 0.8057\n",
            "Epoch 541/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8520 - val_loss: 0.8093\n",
            "Epoch 542/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8351 - val_loss: 0.8833\n",
            "Epoch 543/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8613 - val_loss: 0.9607\n",
            "Epoch 544/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8414 - val_loss: 0.8362\n",
            "Epoch 545/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8314 - val_loss: 0.8374\n",
            "Epoch 546/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8647 - val_loss: 0.8828\n",
            "Epoch 547/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8473 - val_loss: 0.8027\n",
            "Epoch 548/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8253 - val_loss: 0.8189\n",
            "Epoch 549/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8290 - val_loss: 0.8127\n",
            "Epoch 550/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8344 - val_loss: 0.8025\n",
            "Epoch 551/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8281 - val_loss: 0.8022\n",
            "Epoch 552/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8245 - val_loss: 0.8219\n",
            "Epoch 553/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8261 - val_loss: 0.8206\n",
            "Epoch 554/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8339 - val_loss: 0.8052\n",
            "Epoch 555/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.8337 - val_loss: 0.8156\n",
            "Epoch 556/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8279 - val_loss: 0.8247\n",
            "Epoch 557/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8475 - val_loss: 0.8399\n",
            "Epoch 558/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8274 - val_loss: 0.8057\n",
            "Epoch 559/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8230 - val_loss: 0.8219\n",
            "Epoch 560/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8210 - val_loss: 0.8001\n",
            "Epoch 561/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 0.8253 - val_loss: 0.8106\n",
            "Epoch 562/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8493 - val_loss: 0.7992\n",
            "Epoch 563/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8239 - val_loss: 0.8059\n",
            "Epoch 564/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8218 - val_loss: 0.8467\n",
            "Epoch 565/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8248 - val_loss: 0.8232\n",
            "Epoch 566/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8241 - val_loss: 0.8545\n",
            "Epoch 567/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8291 - val_loss: 0.8048\n",
            "Epoch 568/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8215 - val_loss: 0.8418\n",
            "Epoch 569/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8300 - val_loss: 0.8203\n",
            "Epoch 570/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8194 - val_loss: 0.8304\n",
            "Epoch 571/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8371 - val_loss: 0.8250\n",
            "Epoch 572/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8479 - val_loss: 0.8130\n",
            "Epoch 573/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8451 - val_loss: 0.8103\n",
            "Epoch 574/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8677 - val_loss: 0.8451\n",
            "Epoch 575/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8432 - val_loss: 0.8013\n",
            "Epoch 576/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8269 - val_loss: 0.8494\n",
            "Epoch 577/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8189 - val_loss: 0.7959\n",
            "Epoch 578/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8204 - val_loss: 0.7985\n",
            "Epoch 579/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8209 - val_loss: 0.8035\n",
            "Epoch 580/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8142 - val_loss: 0.8039\n",
            "Epoch 581/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.8363 - val_loss: 0.8080\n",
            "Epoch 582/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8214 - val_loss: 0.8293\n",
            "Epoch 583/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8220 - val_loss: 0.8127\n",
            "Epoch 584/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8159 - val_loss: 0.8281\n",
            "Epoch 585/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.8200 - val_loss: 0.8012\n",
            "Epoch 586/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8211 - val_loss: 0.8147\n",
            "Epoch 587/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8133 - val_loss: 0.8176\n",
            "Epoch 588/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8133 - val_loss: 0.8235\n",
            "Epoch 589/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8256 - val_loss: 0.8296\n",
            "Epoch 590/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8117 - val_loss: 0.8417\n",
            "Epoch 591/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8205 - val_loss: 0.8292\n",
            "Epoch 592/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8207 - val_loss: 0.8011\n",
            "Epoch 593/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8191 - val_loss: 0.8172\n",
            "Epoch 594/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8485 - val_loss: 0.8413\n",
            "Epoch 595/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8377 - val_loss: 0.8039\n",
            "Epoch 596/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8363 - val_loss: 0.7950\n",
            "Epoch 597/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8272 - val_loss: 0.8003\n",
            "Epoch 598/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8139 - val_loss: 0.8191\n",
            "Epoch 599/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8363 - val_loss: 0.7978\n",
            "Epoch 600/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8161 - val_loss: 0.7958\n",
            "Epoch 601/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8113 - val_loss: 0.8812\n",
            "Epoch 602/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8111 - val_loss: 0.7940\n",
            "Epoch 603/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8157 - val_loss: 0.7969\n",
            "Epoch 604/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8138 - val_loss: 0.8044\n",
            "Epoch 605/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.8075 - val_loss: 0.7958\n",
            "Epoch 606/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8082 - val_loss: 0.8080\n",
            "Epoch 607/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8113 - val_loss: 0.8344\n",
            "Epoch 608/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8052 - val_loss: 0.8304\n",
            "Epoch 609/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8109 - val_loss: 0.8429\n",
            "Epoch 610/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8074 - val_loss: 0.8339\n",
            "Epoch 611/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8046 - val_loss: 0.8103\n",
            "Epoch 612/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8054 - val_loss: 0.7949\n",
            "Epoch 613/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8177 - val_loss: 0.8603\n",
            "Epoch 614/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8273 - val_loss: 0.8554\n",
            "Epoch 615/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8279 - val_loss: 0.8482\n",
            "Epoch 616/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8149 - val_loss: 0.7953\n",
            "Epoch 617/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8097 - val_loss: 0.8562\n",
            "Epoch 618/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8026 - val_loss: 0.7922\n",
            "Epoch 619/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8044 - val_loss: 0.8321\n",
            "Epoch 620/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8064 - val_loss: 0.7993\n",
            "Epoch 621/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8070 - val_loss: 0.7924\n",
            "Epoch 622/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8005 - val_loss: 0.7945\n",
            "Epoch 623/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.8004 - val_loss: 0.8135\n",
            "Epoch 624/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8080 - val_loss: 0.7981\n",
            "Epoch 625/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8179 - val_loss: 0.8331\n",
            "Epoch 626/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8063 - val_loss: 0.7922\n",
            "Epoch 627/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8082 - val_loss: 0.8141\n",
            "Epoch 628/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.8174 - val_loss: 0.8136\n",
            "Epoch 629/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.8369 - val_loss: 0.7962\n",
            "Epoch 630/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7984 - val_loss: 0.7851\n",
            "Epoch 631/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7978 - val_loss: 0.7940\n",
            "Epoch 632/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7954 - val_loss: 0.7888\n",
            "Epoch 633/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.8095 - val_loss: 0.9109\n",
            "Epoch 634/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8174 - val_loss: 0.8166\n",
            "Epoch 635/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7990 - val_loss: 0.8308\n",
            "Epoch 636/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.7970 - val_loss: 0.8272\n",
            "Epoch 637/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7992 - val_loss: 0.8361\n",
            "Epoch 638/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.7909 - val_loss: 0.8145\n",
            "Epoch 639/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7994 - val_loss: 0.7888\n",
            "Epoch 640/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8104 - val_loss: 0.7902\n",
            "Epoch 641/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7918 - val_loss: 0.7818\n",
            "Epoch 642/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.8048 - val_loss: 0.8742\n",
            "Epoch 643/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7973 - val_loss: 0.7873\n",
            "Epoch 644/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7816 - val_loss: 0.8228\n",
            "Epoch 645/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7913 - val_loss: 0.7871\n",
            "Epoch 646/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7917 - val_loss: 0.7937\n",
            "Epoch 647/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7854 - val_loss: 0.8408\n",
            "Epoch 648/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7992 - val_loss: 0.8490\n",
            "Epoch 649/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7936 - val_loss: 0.7886\n",
            "Epoch 650/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7913 - val_loss: 0.8580\n",
            "Epoch 651/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7829 - val_loss: 0.8011\n",
            "Epoch 652/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7873 - val_loss: 0.7909\n",
            "Epoch 653/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7885 - val_loss: 0.7955\n",
            "Epoch 654/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7783 - val_loss: 0.8043\n",
            "Epoch 655/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7871 - val_loss: 0.8080\n",
            "Epoch 656/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.7762 - val_loss: 0.7923\n",
            "Epoch 657/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7838 - val_loss: 0.8100\n",
            "Epoch 658/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7768 - val_loss: 0.7909\n",
            "Epoch 659/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7737 - val_loss: 0.8047\n",
            "Epoch 660/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7803 - val_loss: 0.8301\n",
            "Epoch 661/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.7805 - val_loss: 0.7798\n",
            "Epoch 662/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7704 - val_loss: 0.7837\n",
            "Epoch 663/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7735 - val_loss: 0.7778\n",
            "Epoch 664/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7829 - val_loss: 0.7861\n",
            "Epoch 665/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7707 - val_loss: 0.7785\n",
            "Epoch 666/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7741 - val_loss: 0.7876\n",
            "Epoch 667/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7745 - val_loss: 0.7937\n",
            "Epoch 668/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7842 - val_loss: 0.7965\n",
            "Epoch 669/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7735 - val_loss: 0.7999\n",
            "Epoch 670/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7695 - val_loss: 0.7816\n",
            "Epoch 671/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.7789 - val_loss: 0.7803\n",
            "Epoch 672/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7780 - val_loss: 0.9419\n",
            "Epoch 673/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7986 - val_loss: 0.8508\n",
            "Epoch 674/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7912 - val_loss: 0.8344\n",
            "Epoch 675/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7806 - val_loss: 0.7745\n",
            "Epoch 676/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7673 - val_loss: 0.7979\n",
            "Epoch 677/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7617 - val_loss: 0.7875\n",
            "Epoch 678/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7590 - val_loss: 0.7738\n",
            "Epoch 679/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.7626 - val_loss: 0.8447\n",
            "Epoch 680/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7633 - val_loss: 0.7871\n",
            "Epoch 681/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7733 - val_loss: 0.7751\n",
            "Epoch 682/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7664 - val_loss: 0.7940\n",
            "Epoch 683/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7594 - val_loss: 0.7809\n",
            "Epoch 684/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7618 - val_loss: 0.7895\n",
            "Epoch 685/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7607 - val_loss: 0.8031\n",
            "Epoch 686/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7694 - val_loss: 0.7791\n",
            "Epoch 687/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7525 - val_loss: 0.7745\n",
            "Epoch 688/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7687 - val_loss: 0.7761\n",
            "Epoch 689/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7730 - val_loss: 0.7661\n",
            "Epoch 690/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7516 - val_loss: 0.8064\n",
            "Epoch 691/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7537 - val_loss: 0.7664\n",
            "Epoch 692/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7568 - val_loss: 0.7720\n",
            "Epoch 693/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7520 - val_loss: 0.7758\n",
            "Epoch 694/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7472 - val_loss: 0.7663\n",
            "Epoch 695/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7702 - val_loss: 0.7737\n",
            "Epoch 696/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7470 - val_loss: 0.7869\n",
            "Epoch 697/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7472 - val_loss: 0.7781\n",
            "Epoch 698/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7493 - val_loss: 0.7601\n",
            "Epoch 699/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7486 - val_loss: 0.8282\n",
            "Epoch 700/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7536 - val_loss: 0.7994\n",
            "Epoch 701/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7516 - val_loss: 0.7795\n",
            "Epoch 702/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7552 - val_loss: 0.7610\n",
            "Epoch 703/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7413 - val_loss: 0.7916\n",
            "Epoch 704/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7469 - val_loss: 0.8057\n",
            "Epoch 705/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7522 - val_loss: 0.7981\n",
            "Epoch 706/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7445 - val_loss: 0.7750\n",
            "Epoch 707/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7496 - val_loss: 0.8325\n",
            "Epoch 708/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7694 - val_loss: 0.7577\n",
            "Epoch 709/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7575 - val_loss: 0.7694\n",
            "Epoch 710/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7480 - val_loss: 0.7515\n",
            "Epoch 711/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7377 - val_loss: 0.7958\n",
            "Epoch 712/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7483 - val_loss: 0.7527\n",
            "Epoch 713/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7424 - val_loss: 0.7799\n",
            "Epoch 714/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7446 - val_loss: 0.7588\n",
            "Epoch 715/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7406 - val_loss: 0.8175\n",
            "Epoch 716/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7475 - val_loss: 0.8031\n",
            "Epoch 717/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7467 - val_loss: 0.8285\n",
            "Epoch 718/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7490 - val_loss: 0.7645\n",
            "Epoch 719/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7387 - val_loss: 0.7655\n",
            "Epoch 720/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7360 - val_loss: 0.8094\n",
            "Epoch 721/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7358 - val_loss: 0.7719\n",
            "Epoch 722/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7460 - val_loss: 0.7565\n",
            "Epoch 723/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7314 - val_loss: 0.7479\n",
            "Epoch 724/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7456 - val_loss: 0.7594\n",
            "Epoch 725/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7605 - val_loss: 0.7821\n",
            "Epoch 726/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7594 - val_loss: 0.8789\n",
            "Epoch 727/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7378 - val_loss: 0.7493\n",
            "Epoch 728/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7373 - val_loss: 0.7490\n",
            "Epoch 729/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.7249 - val_loss: 0.7889\n",
            "Epoch 730/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7414 - val_loss: 0.7801\n",
            "Epoch 731/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7304 - val_loss: 0.8018\n",
            "Epoch 732/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7241 - val_loss: 0.7766\n",
            "Epoch 733/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7329 - val_loss: 0.7931\n",
            "Epoch 734/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7290 - val_loss: 0.7446\n",
            "Epoch 735/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7314 - val_loss: 0.7559\n",
            "Epoch 736/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7263 - val_loss: 0.8213\n",
            "Epoch 737/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7354 - val_loss: 0.7662\n",
            "Epoch 738/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7349 - val_loss: 0.7444\n",
            "Epoch 739/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7436 - val_loss: 0.7343\n",
            "Epoch 740/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7264 - val_loss: 0.7483\n",
            "Epoch 741/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7334 - val_loss: 0.7378\n",
            "Epoch 742/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7407 - val_loss: 0.7769\n",
            "Epoch 743/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7206 - val_loss: 0.7422\n",
            "Epoch 744/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7266 - val_loss: 0.7445\n",
            "Epoch 745/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7226 - val_loss: 0.7388\n",
            "Epoch 746/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7286 - val_loss: 0.7344\n",
            "Epoch 747/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7248 - val_loss: 0.7582\n",
            "Epoch 748/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7240 - val_loss: 0.7395\n",
            "Epoch 749/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7161 - val_loss: 0.7424\n",
            "Epoch 750/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.7181 - val_loss: 0.7426\n",
            "Epoch 751/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7193 - val_loss: 0.7537\n",
            "Epoch 752/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7263 - val_loss: 0.7375\n",
            "Epoch 753/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7244 - val_loss: 0.7453\n",
            "Epoch 754/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7122 - val_loss: 0.7324\n",
            "Epoch 755/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7207 - val_loss: 0.7266\n",
            "Epoch 756/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7203 - val_loss: 0.7551\n",
            "Epoch 757/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7296 - val_loss: 0.8491\n",
            "Epoch 758/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7305 - val_loss: 0.7446\n",
            "Epoch 759/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7292 - val_loss: 0.7425\n",
            "Epoch 760/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7188 - val_loss: 0.7840\n",
            "Epoch 761/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7165 - val_loss: 0.7260\n",
            "Epoch 762/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7105 - val_loss: 0.7399\n",
            "Epoch 763/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7189 - val_loss: 0.7280\n",
            "Epoch 764/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7107 - val_loss: 0.7506\n",
            "Epoch 765/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7192 - val_loss: 0.7237\n",
            "Epoch 766/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7171 - val_loss: 0.7271\n",
            "Epoch 767/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7090 - val_loss: 0.7306\n",
            "Epoch 768/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7363 - val_loss: 0.7315\n",
            "Epoch 769/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7099 - val_loss: 0.7483\n",
            "Epoch 770/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7072 - val_loss: 0.7257\n",
            "Epoch 771/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.7290 - val_loss: 0.7267\n",
            "Epoch 772/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7043 - val_loss: 0.7970\n",
            "Epoch 773/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7175 - val_loss: 0.7432\n",
            "Epoch 774/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7227 - val_loss: 0.7386\n",
            "Epoch 775/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7223 - val_loss: 0.7289\n",
            "Epoch 776/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7022 - val_loss: 0.7255\n",
            "Epoch 777/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7047 - val_loss: 0.7218\n",
            "Epoch 778/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7066 - val_loss: 0.7297\n",
            "Epoch 779/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7049 - val_loss: 0.7800\n",
            "Epoch 780/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7080 - val_loss: 0.7249\n",
            "Epoch 781/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7033 - val_loss: 0.7197\n",
            "Epoch 782/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7051 - val_loss: 0.7279\n",
            "Epoch 783/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6957 - val_loss: 0.7275\n",
            "Epoch 784/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7108 - val_loss: 0.7699\n",
            "Epoch 785/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7116 - val_loss: 0.7523\n",
            "Epoch 786/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7031 - val_loss: 0.7237\n",
            "Epoch 787/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7055 - val_loss: 0.7235\n",
            "Epoch 788/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7229 - val_loss: 0.7218\n",
            "Epoch 789/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7063 - val_loss: 0.7288\n",
            "Epoch 790/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.7130 - val_loss: 0.7806\n",
            "Epoch 791/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.7221 - val_loss: 0.7428\n",
            "Epoch 792/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7013 - val_loss: 0.7359\n",
            "Epoch 793/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.7162 - val_loss: 0.7241\n",
            "Epoch 794/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.7133 - val_loss: 0.7840\n",
            "Epoch 795/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.7147 - val_loss: 0.8182\n",
            "Epoch 796/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.7041 - val_loss: 0.7222\n",
            "Epoch 797/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.6900 - val_loss: 0.7534\n",
            "Epoch 798/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6949 - val_loss: 0.7199\n",
            "Epoch 799/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6999 - val_loss: 0.7212\n",
            "Epoch 800/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 0.7233 - val_loss: 0.7201\n",
            "Epoch 801/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6960 - val_loss: 0.7241\n",
            "Epoch 802/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6908 - val_loss: 0.7202\n",
            "Epoch 803/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7029 - val_loss: 0.7223\n",
            "Epoch 804/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6973 - val_loss: 0.8399\n",
            "Epoch 805/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7063 - val_loss: 0.7219\n",
            "Epoch 806/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.6957 - val_loss: 0.7258\n",
            "Epoch 807/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.7003 - val_loss: 0.7362\n",
            "Epoch 808/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6911 - val_loss: 0.7224\n",
            "Epoch 809/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6901 - val_loss: 0.7357\n",
            "Epoch 810/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6929 - val_loss: 0.7609\n",
            "Epoch 811/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6951 - val_loss: 0.7231\n",
            "Epoch 812/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6845 - val_loss: 0.7224\n",
            "Epoch 813/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 0.6958 - val_loss: 0.7680\n",
            "Epoch 814/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6837 - val_loss: 0.7204\n",
            "Epoch 815/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6894 - val_loss: 0.7829\n",
            "Epoch 816/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6931 - val_loss: 0.7206\n",
            "Epoch 817/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.6803 - val_loss: 0.7893\n",
            "Epoch 818/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6866 - val_loss: 0.7271\n",
            "Epoch 819/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6849 - val_loss: 0.7215\n",
            "Epoch 820/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6851 - val_loss: 0.8111\n",
            "Epoch 821/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.7047 - val_loss: 0.7176\n",
            "Epoch 822/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6776 - val_loss: 0.7276\n",
            "Epoch 823/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6777 - val_loss: 0.7208\n",
            "Epoch 824/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6784 - val_loss: 0.7419\n",
            "Epoch 825/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6747 - val_loss: 0.7833\n",
            "Epoch 826/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6927 - val_loss: 0.7373\n",
            "Epoch 827/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6768 - val_loss: 0.7191\n",
            "Epoch 828/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6851 - val_loss: 0.7375\n",
            "Epoch 829/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6820 - val_loss: 0.7754\n",
            "Epoch 830/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6805 - val_loss: 0.7762\n",
            "Epoch 831/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6790 - val_loss: 0.7314\n",
            "Epoch 832/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6930 - val_loss: 0.7939\n",
            "Epoch 833/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6779 - val_loss: 0.7296\n",
            "Epoch 834/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6639 - val_loss: 0.7265\n",
            "Epoch 835/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6820 - val_loss: 0.7236\n",
            "Epoch 836/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6825 - val_loss: 0.8552\n",
            "Epoch 837/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6759 - val_loss: 0.7451\n",
            "Epoch 838/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6812 - val_loss: 0.7259\n",
            "Epoch 839/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6882 - val_loss: 0.7301\n",
            "Epoch 840/1000\n",
            "26/26 [==============================] - 1s 32ms/step - loss: 0.6759 - val_loss: 0.7363\n",
            "Epoch 841/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.6833 - val_loss: 0.7149\n",
            "Epoch 842/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.6729 - val_loss: 0.7381\n",
            "Epoch 843/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6641 - val_loss: 0.7317\n",
            "Epoch 844/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6696 - val_loss: 0.7189\n",
            "Epoch 845/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6819 - val_loss: 0.7836\n",
            "Epoch 846/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6787 - val_loss: 0.7348\n",
            "Epoch 847/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6693 - val_loss: 0.7140\n",
            "Epoch 848/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6624 - val_loss: 0.7206\n",
            "Epoch 849/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6779 - val_loss: 0.7724\n",
            "Epoch 850/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6844 - val_loss: 0.7606\n",
            "Epoch 851/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6619 - val_loss: 0.7315\n",
            "Epoch 852/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6606 - val_loss: 0.7318\n",
            "Epoch 853/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6628 - val_loss: 0.7229\n",
            "Epoch 854/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6552 - val_loss: 0.7185\n",
            "Epoch 855/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6598 - val_loss: 0.7823\n",
            "Epoch 856/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6585 - val_loss: 0.7178\n",
            "Epoch 857/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6599 - val_loss: 0.7219\n",
            "Epoch 858/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6556 - val_loss: 0.7291\n",
            "Epoch 859/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6607 - val_loss: 0.7101\n",
            "Epoch 860/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6541 - val_loss: 0.7452\n",
            "Epoch 861/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6550 - val_loss: 0.7634\n",
            "Epoch 862/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6618 - val_loss: 0.7246\n",
            "Epoch 863/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6537 - val_loss: 0.7154\n",
            "Epoch 864/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6609 - val_loss: 0.7545\n",
            "Epoch 865/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6595 - val_loss: 0.7191\n",
            "Epoch 866/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6554 - val_loss: 0.7385\n",
            "Epoch 867/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6610 - val_loss: 0.7140\n",
            "Epoch 868/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6513 - val_loss: 0.7410\n",
            "Epoch 869/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6498 - val_loss: 0.7173\n",
            "Epoch 870/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6553 - val_loss: 0.7435\n",
            "Epoch 871/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6446 - val_loss: 0.7222\n",
            "Epoch 872/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6526 - val_loss: 0.7210\n",
            "Epoch 873/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6612 - val_loss: 0.7400\n",
            "Epoch 874/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6556 - val_loss: 0.7215\n",
            "Epoch 875/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6616 - val_loss: 0.7079\n",
            "Epoch 876/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6529 - val_loss: 0.7144\n",
            "Epoch 877/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6412 - val_loss: 0.7267\n",
            "Epoch 878/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6494 - val_loss: 0.7076\n",
            "Epoch 879/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6487 - val_loss: 0.7423\n",
            "Epoch 880/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6464 - val_loss: 0.7227\n",
            "Epoch 881/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6442 - val_loss: 0.7139\n",
            "Epoch 882/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6480 - val_loss: 0.7099\n",
            "Epoch 883/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6518 - val_loss: 0.7236\n",
            "Epoch 884/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6531 - val_loss: 0.7276\n",
            "Epoch 885/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6454 - val_loss: 0.7118\n",
            "Epoch 886/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.6450 - val_loss: 0.7189\n",
            "Epoch 887/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6385 - val_loss: 0.7194\n",
            "Epoch 888/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6523 - val_loss: 0.7032\n",
            "Epoch 889/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6557 - val_loss: 0.7726\n",
            "Epoch 890/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6413 - val_loss: 0.7111\n",
            "Epoch 891/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6393 - val_loss: 0.7180\n",
            "Epoch 892/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6526 - val_loss: 0.7424\n",
            "Epoch 893/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6350 - val_loss: 0.7085\n",
            "Epoch 894/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6372 - val_loss: 0.7006\n",
            "Epoch 895/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6414 - val_loss: 0.7200\n",
            "Epoch 896/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6453 - val_loss: 0.7422\n",
            "Epoch 897/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6381 - val_loss: 0.7077\n",
            "Epoch 898/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6386 - val_loss: 0.7335\n",
            "Epoch 899/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6362 - val_loss: 0.7104\n",
            "Epoch 900/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6367 - val_loss: 0.7035\n",
            "Epoch 901/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6380 - val_loss: 0.7189\n",
            "Epoch 902/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6324 - val_loss: 0.7053\n",
            "Epoch 903/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6457 - val_loss: 0.7008\n",
            "Epoch 904/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6312 - val_loss: 0.7471\n",
            "Epoch 905/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6347 - val_loss: 0.7284\n",
            "Epoch 906/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6409 - val_loss: 0.7383\n",
            "Epoch 907/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6395 - val_loss: 0.7277\n",
            "Epoch 908/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6346 - val_loss: 0.7045\n",
            "Epoch 909/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6248 - val_loss: 0.7139\n",
            "Epoch 910/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6305 - val_loss: 0.6955\n",
            "Epoch 911/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.6306 - val_loss: 0.6999\n",
            "Epoch 912/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6269 - val_loss: 0.7136\n",
            "Epoch 913/1000\n",
            "26/26 [==============================] - 1s 25ms/step - loss: 0.6291 - val_loss: 0.7022\n",
            "Epoch 914/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6322 - val_loss: 0.6921\n",
            "Epoch 915/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6327 - val_loss: 0.7338\n",
            "Epoch 916/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6348 - val_loss: 0.7191\n",
            "Epoch 917/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6209 - val_loss: 0.7073\n",
            "Epoch 918/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6370 - val_loss: 0.6979\n",
            "Epoch 919/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6263 - val_loss: 0.7360\n",
            "Epoch 920/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6332 - val_loss: 0.7277\n",
            "Epoch 921/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6351 - val_loss: 0.7305\n",
            "Epoch 922/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6325 - val_loss: 0.6978\n",
            "Epoch 923/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6180 - val_loss: 0.7109\n",
            "Epoch 924/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6328 - val_loss: 0.7390\n",
            "Epoch 925/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6224 - val_loss: 0.6983\n",
            "Epoch 926/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6200 - val_loss: 0.6997\n",
            "Epoch 927/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6224 - val_loss: 0.7630\n",
            "Epoch 928/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6361 - val_loss: 0.7957\n",
            "Epoch 929/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6257 - val_loss: 0.7105\n",
            "Epoch 930/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6188 - val_loss: 0.6955\n",
            "Epoch 931/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.6253 - val_loss: 0.6890\n",
            "Epoch 932/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6195 - val_loss: 0.7606\n",
            "Epoch 933/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6151 - val_loss: 0.7158\n",
            "Epoch 934/1000\n",
            "26/26 [==============================] - 1s 30ms/step - loss: 0.6255 - val_loss: 0.7152\n",
            "Epoch 935/1000\n",
            "26/26 [==============================] - 1s 31ms/step - loss: 0.6202 - val_loss: 0.7065\n",
            "Epoch 936/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6154 - val_loss: 0.7188\n",
            "Epoch 937/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6360 - val_loss: 0.6955\n",
            "Epoch 938/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6287 - val_loss: 0.7074\n",
            "Epoch 939/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6262 - val_loss: 0.6922\n",
            "Epoch 940/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6153 - val_loss: 0.7130\n",
            "Epoch 941/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6083 - val_loss: 0.6971\n",
            "Epoch 942/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6112 - val_loss: 0.7331\n",
            "Epoch 943/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6154 - val_loss: 0.6921\n",
            "Epoch 944/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6220 - val_loss: 0.7041\n",
            "Epoch 945/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6166 - val_loss: 0.7070\n",
            "Epoch 946/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6123 - val_loss: 0.7375\n",
            "Epoch 947/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6230 - val_loss: 0.7606\n",
            "Epoch 948/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6190 - val_loss: 0.7048\n",
            "Epoch 949/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6075 - val_loss: 0.6869\n",
            "Epoch 950/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6081 - val_loss: 0.6957\n",
            "Epoch 951/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6228 - val_loss: 0.6869\n",
            "Epoch 952/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6260 - val_loss: 0.7171\n",
            "Epoch 953/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6043 - val_loss: 0.6916\n",
            "Epoch 954/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6051 - val_loss: 0.6889\n",
            "Epoch 955/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6070 - val_loss: 0.6971\n",
            "Epoch 956/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6042 - val_loss: 0.6947\n",
            "Epoch 957/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6195 - val_loss: 0.6982\n",
            "Epoch 958/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6274 - val_loss: 0.6927\n",
            "Epoch 959/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6074 - val_loss: 0.7479\n",
            "Epoch 960/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.6067 - val_loss: 0.6963\n",
            "Epoch 961/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6052 - val_loss: 0.7015\n",
            "Epoch 962/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6111 - val_loss: 0.7016\n",
            "Epoch 963/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6046 - val_loss: 0.6943\n",
            "Epoch 964/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6039 - val_loss: 0.6908\n",
            "Epoch 965/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.6020 - val_loss: 0.7128\n",
            "Epoch 966/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6106 - val_loss: 0.6882\n",
            "Epoch 967/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6050 - val_loss: 0.7272\n",
            "Epoch 968/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6019 - val_loss: 0.6894\n",
            "Epoch 969/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6109 - val_loss: 0.6932\n",
            "Epoch 970/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6083 - val_loss: 0.6979\n",
            "Epoch 971/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.6011 - val_loss: 0.7029\n",
            "Epoch 972/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.5974 - val_loss: 0.6912\n",
            "Epoch 973/1000\n",
            "26/26 [==============================] - 1s 23ms/step - loss: 0.5996 - val_loss: 0.6832\n",
            "Epoch 974/1000\n",
            "26/26 [==============================] - 1s 24ms/step - loss: 0.6024 - val_loss: 0.7176\n",
            "Epoch 975/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6192 - val_loss: 0.7124\n",
            "Epoch 976/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6240 - val_loss: 0.7320\n",
            "Epoch 977/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6133 - val_loss: 0.6900\n",
            "Epoch 978/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6091 - val_loss: 0.6836\n",
            "Epoch 979/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.6087 - val_loss: 0.7292\n",
            "Epoch 980/1000\n",
            "26/26 [==============================] - 1s 33ms/step - loss: 0.5942 - val_loss: 0.7205\n",
            "Epoch 981/1000\n",
            "26/26 [==============================] - 1s 29ms/step - loss: 0.5941 - val_loss: 0.6877\n",
            "Epoch 982/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6087 - val_loss: 0.7006\n",
            "Epoch 983/1000\n",
            "26/26 [==============================] - 1s 28ms/step - loss: 0.6072 - val_loss: 0.7087\n",
            "Epoch 984/1000\n",
            "26/26 [==============================] - 1s 27ms/step - loss: 0.5976 - val_loss: 0.6848\n",
            "Epoch 985/1000\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.5907 - val_loss: 0.6962\n",
            "Epoch 986/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6026 - val_loss: 0.7063\n",
            "Epoch 987/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6016 - val_loss: 0.6954\n",
            "Epoch 988/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5989 - val_loss: 0.7055\n",
            "Epoch 989/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6007 - val_loss: 0.7172\n",
            "Epoch 990/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.6045 - val_loss: 0.6986\n",
            "Epoch 991/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.5954 - val_loss: 0.6995\n",
            "Epoch 992/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5957 - val_loss: 0.6821\n",
            "Epoch 993/1000\n",
            "26/26 [==============================] - 1s 20ms/step - loss: 0.5927 - val_loss: 0.7159\n",
            "Epoch 994/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.6107 - val_loss: 0.6940\n",
            "Epoch 995/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5891 - val_loss: 0.7174\n",
            "Epoch 996/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5943 - val_loss: 0.6985\n",
            "Epoch 997/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5909 - val_loss: 0.6855\n",
            "Epoch 998/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.5880 - val_loss: 0.6891\n",
            "Epoch 999/1000\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.5853 - val_loss: 0.6968\n",
            "Epoch 1000/1000\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.5896 - val_loss: 0.7135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "import time\n",
        "st = time.time()\n",
        "p1 = np.array(model(X_val)).flatten()\n",
        "end = time.time()\n",
        "# print(end, st, len(p1))\n",
        "print((end-st)/len(p1))\n",
        "p2 = np.array(model(X_train)).flatten()\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRonsAco2pfY",
        "outputId": "c53e0737-8dfa-4de0-f004-edd240fc9bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.682844047086785e-05\n",
            "(1660, 180, 1)\n",
            "(415, 180, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import kendalltau\n",
        "# print(np.corrcoef(p2, Y_train), stats.spearmanr(p2, Y_train), kendalltau(p2,Y_train).correlation)\n",
        "print(np.corrcoef(p1, Y_val)[1][0], stats.spearmanr(p1, Y_val).correlation, kendalltau(p1,Y_val).correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJps7jMA2xJX",
        "outputId": "3063b255-0900-4ecd-842e-2fadedac60d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7500975613871322 0.7475940112412154 0.5568566268046643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"audio_dm_3_featu_.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "UQBlBzFT2x38",
        "outputId": "03f5b02c-f713-41c6-89d8-4c1c141faf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}